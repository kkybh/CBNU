1. ì§€ëŠ¥í™” ê¸°ìˆ  êµ¬í˜„ ì£¼ìš” ë‹¨ê³„
ë¬¸ì œ ì •ì˜ ë° ëª©í‘œ ì„¤ì •

í•´ê²°í•  ë¹„ì¦ˆë‹ˆìŠ¤ ë¬¸ì œë‚˜ ê³µí•™ì  ê³¼ì œ ëª…í™•í™”

ì„±ëŠ¥ ëª©í‘œ(ì •í™•ë„, ì†ë„, ë¹„ìš© ë“±) ìˆ˜ë¦½

ë°ì´í„° ìˆ˜ì§‘ ë° ì „ì²˜ë¦¬

ì„¼ì„œ, ë¡œê·¸, ì´ë¯¸ì§€, í…ìŠ¤íŠ¸ ë“± ë‹¤ì–‘í•œ ë°ì´í„° í™•ë³´

ì´ìƒì¹˜ ì œê±°, ì •ê·œí™”, ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ë¼ë²¨ë§ ë“± ë°ì´í„° í’ˆì§ˆ í–¥ìƒ

íŠ¹ì§• ì¶”ì¶œ ë° ì„ íƒ (Feature Engineering)

ë¬¸ì œ í•´ê²°ì— ì¤‘ìš”í•œ íŠ¹ì„±(ë³€ìˆ˜) ì‹ë³„ ë° ë³€í™˜

ë„ë©”ì¸ ì§€ì‹ ë° ìë™í™” ê¸°ë²• í™œìš©

ëª¨ë¸ ì„¤ê³„ ë° í•™ìŠµ

ì ì ˆí•œ AI/ML ì•Œê³ ë¦¬ì¦˜ ì„ ì • (ì˜ˆ: ë”¥ëŸ¬ë‹, ê²°ì •íŠ¸ë¦¬, SVM ë“±)

í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ êµì°¨ ê²€ì¦ ìˆ˜í–‰

ëª¨ë¸ í‰ê°€ ë° ê²€ì¦

í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ í‰ê°€(ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“±)

ì˜¤ë²„í”¼íŒ… ë°©ì§€ ë° ëª¨ë¸ ì¼ë°˜í™” ì ê²€

ì‹œìŠ¤í…œ í†µí•© ë° ë°°í¬

ì˜ˆì¸¡/ë¶„ë¥˜ ëª¨ë¸ì„ ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì—°ê²° (API, ì—£ì§€ ë””ë°”ì´ìŠ¤, í´ë¼ìš°ë“œ ë“±)

ì‹¤ì‹œê°„ ì²˜ë¦¬, ëª¨ë‹ˆí„°ë§ ì²´ê³„ êµ¬ì¶•

ìš´ì˜ ë° ì§€ì† ê°œì„ 

ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì£¼ê¸°ì  ëª¨ë¸ ì¬í•™ìŠµ

ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜ ë° ì‹ ê·œ ê¸°ëŠ¥ ì¶”ê°€

2. ì§€ëŠ¥í™” ê¸°ìˆ  ì ìš© ì‚¬ë¡€
ìŠ¤ë§ˆíŠ¸ íŒ©í† ë¦¬: IoT ì„¼ì„œ ë°ì´í„° ê¸°ë°˜ ì„¤ë¹„ ìƒíƒœ ì˜ˆì¸¡ ë° ì´ìƒ íƒì§€

ììœ¨ì£¼í–‰ì°¨: ì¹´ë©”ë¼/ë ˆì´ë” ë°ì´í„°ë¡œ ë„ë¡œ í™˜ê²½ ì¸ì‹ ë° ì£¼í–‰ ì œì–´

í—¬ìŠ¤ì¼€ì–´: í™˜ì ë°”ì´íƒˆ ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ì§ˆë³‘ ì¡°ê¸° ì§„ë‹¨ ë° ë§ì¶¤ ì¹˜ë£Œ

ê¸ˆìœµ: ì´ìƒ ê±°ë˜ íƒì§€, ì‹ ìš© í‰ê°€, ìë™í™”ëœ íˆ¬ì ìë¬¸

ìœ í†µ: ê³ ê° êµ¬ë§¤ íŒ¨í„´ ë¶„ì„ ë° ê°œì¸í™” ì¶”ì²œ ì‹œìŠ¤í…œ

3. êµ¬í˜„ ê¸°ìˆ  ì˜ˆì‹œ
ê¸°ìˆ 	ì„¤ëª… ë° í™œìš© ì˜ˆì‹œ
ë¨¸ì‹ ëŸ¬ë‹ (ML)	ì§€ë„í•™ìŠµ, ë¹„ì§€ë„í•™ìŠµ, ê°•í™”í•™ìŠµ ê¸°ë°˜ ëª¨ë¸ ê°œë°œ
ë”¥ëŸ¬ë‹ (DL)	ì´ë¯¸ì§€ ì¸ì‹, ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“± ë³µì¡í•œ ë¬¸ì œ í•´ê²°
ë¹…ë°ì´í„° ì²˜ë¦¬	ë¶„ì‚° ì»´í“¨íŒ…(Hadoop, Spark)ë¡œ ëŒ€ê·œëª¨ ë°ì´í„° ë¶„ì„
ì—£ì§€ ì»´í“¨íŒ…	IoT ë””ë°”ì´ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ ë°ì´í„° ì²˜ë¦¬ ë° ì˜ì‚¬ê²°ì • ìˆ˜í–‰
í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤	AI ëª¨ë¸ í•™ìŠµ/ë°°í¬, ë°ì´í„° ì €ì¥ ë° API ì„œë¹„ìŠ¤ ì œê³µ
ìë™í™” ë° RPA	ë°˜ë³µ ì—…ë¬´ ìë™í™”, ë°ì´í„° ì…ë ¥ ë° ì²˜ë¦¬ íš¨ìœ¨í™”

ì§€ëŠ¥í™” ê¸°ìˆ ë³„ êµ¬ì²´ êµ¬í˜„ ì½”ë“œ
1. ë¨¸ì‹ ëŸ¬ë‹ (ML) â€” ì˜ì‚¬ê²°ì •íŠ¸ë¦¬ë¡œ ë¶„ë¥˜ ë¬¸ì œ
python
ë³µì‚¬
í¸ì§‘
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# ë°ì´í„° ì¤€ë¹„
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.3, random_state=42)

# ëª¨ë¸ í•™ìŠµ
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
2. ë”¥ëŸ¬ë‹ (DL) â€” Kerasë¡œ ê°„ë‹¨í•œ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡ (Multi-layer Perceptron)
python
ë³µì‚¬
í¸ì§‘
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
import numpy as np

# ë°ì´í„° ì¤€ë¹„
iris = load_iris()
X = iris.data
y = iris.target.reshape(-1, 1)
encoder = OneHotEncoder(sparse=False)
y = encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ëª¨ë¸ ì„¤ê³„
model = Sequential([
    Dense(10, activation='relu', input_shape=(4,)),
    Dense(10, activation='relu'),
    Dense(3, activation='softmax')
])

# ì»´íŒŒì¼ ë° í•™ìŠµ
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=0)

# í‰ê°€
loss, acc = model.evaluate(X_test, y_test)
print("Test Accuracy:", acc)
3. ë¹…ë°ì´í„° ì²˜ë¦¬ â€” PySparkë¡œ ê°„ë‹¨í•œ ë°ì´í„° ì½ê¸° ë° í•„í„°ë§
python
ë³µì‚¬
í¸ì§‘
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("BigDataExample").getOrCreate()

# ë°ì´í„° ì½ê¸° (CSV ì˜ˆì‹œ)
df = spark.read.csv("sample_data.csv", header=True, inferSchema=True)

# ê°„ë‹¨ í•„í„°ë§
filtered = df.filter(df['value'] > 100)
filtered.show()

spark.stop()
4. IoT ì—£ì§€ ì»´í“¨íŒ… â€” Raspberry Piì—ì„œ ê°„ë‹¨ ì„¼ì„œ ë°ì´í„° ì½ê¸° (ê°€ìƒ ì˜ˆ)
python
ë³µì‚¬
í¸ì§‘
import random
import time

def read_sensor():
    # ì‹¤ì œë¡œëŠ” ì„¼ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ
    return random.uniform(20.0, 30.0)  # ì˜¨ë„ê°’ ì˜ˆì‹œ

while True:
    temp = read_sensor()
    print(f"Current Temperature: {temp:.2f} C")
    # ê°„ë‹¨ ì´ìƒ íƒì§€
    if temp > 28.0:
        print("Warning: High temperature detected!")
    time.sleep(5)
5. í´ë¼ìš°ë“œ AI ëª¨ë¸ ë°°í¬ â€” Flask API ì˜ˆì‹œ
python
ë³µì‚¬
í¸ì§‘
from flask import Flask, request, jsonify
import joblib

app = Flask(__name__)

# ë¯¸ë¦¬ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model = joblib.load('model.pkl')

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    features = data['features']
    prediction = model.predict([features])
    return jsonify({'prediction': int(prediction[0])})

if __name__ == '__main__':
    app.run(debug=True)

1. ìì—°ì–´ì²˜ë¦¬ ê¸°ë³¸ ì½”ë“œ ì˜ˆì œ (í…ìŠ¤íŠ¸ ê°ì„±ë¶„ì„)
íŒŒì´ì¬ì˜ transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì‚¬ì „í•™ìŠµëœ BERT ëª¨ë¸ë¡œ ê°„ë‹¨ ê°ì„± ë¶„ì„í•´ë³´ê¸°.

python
ë³µì‚¬
í¸ì§‘
from transformers import pipeline

# ì‚¬ì „í•™ìŠµëœ ê°ì„±ë¶„ì„ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
classifier = pipeline('sentiment-analysis')

texts = [
    "I love this product! It's amazing.",
    "The movie was terrible and boring.",
    "I feel okay about the service."
]

results = classifier(texts)

for text, res in zip(texts, results):
    print(f"Text: {text}\nSentiment: {res['label']}, Score: {res['score']:.4f}\n")
2. ìì—°ì–´ì²˜ë¦¬ ê³µê°œ ë°ì´í„°ì…‹
IMDb ì˜í™” ë¦¬ë·° ê°ì„±ë¶„ì„ ë°ì´í„°ì…‹

ì˜í™” ë¦¬ë·° í…ìŠ¤íŠ¸ì™€ ê¸ì •/ë¶€ì • ë ˆì´ë¸”

IMDb ë°ì´í„°ì…‹ (TensorFlow Datasets)

Kaggleì˜ Twitter Sentiment Analysis Dataset

íŠ¸ìœ— í…ìŠ¤íŠ¸ì™€ ê°ì„± ë¼ë²¨ í¬í•¨

Kaggle Twitter US Airline Sentiment

ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹ (í•œêµ­ì–´)

í•œêµ­ì–´ ê°ì„± ë¶„ì„ìš© ë¦¬ë·° ë°ì´í„°

ë„¤ì´ë²„ ì˜í™” ë¦¬ë·° ë°ì´í„°

3. ë°ì´í„°ì…‹ ì˜ˆì‹œ: IMDb ê°ì„±ë¶„ì„ (TensorFlowë¡œ ë¶ˆëŸ¬ì˜¤ê¸°)
python
ë³µì‚¬
í¸ì§‘
import tensorflow_datasets as tfds

# IMDb ë¦¬ë·° ë°ì´í„°ì…‹ ë¡œë“œ
dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)

train_data, test_data = dataset['train'], dataset['test']

for text, label in train_data.take(3):
    print("Text:", text.numpy().decode('utf-8'))
    print("Label:", label.numpy())  # 0=ë¶€ì •, 1=ê¸ì •
    print()

í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬

1. ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬
KoNLPy : í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì˜ˆ: Okt, Kkma, Komoran, Hannanum ë“±)

re : ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŠ¹ìˆ˜ë¬¸ì ë“± ì œê±°

nltk : ë¶ˆìš©ì–´(stopwords) ì²˜ë¦¬ ê°€ëŠ¥ (í•œêµ­ì–´ ë¶ˆìš©ì–´ ì§ì ‘ ì •ì˜ ê°€ëŠ¥)

2. ê°„ë‹¨í•œ í•œêµ­ì–´ ì „ì²˜ë¦¬ ì˜ˆì‹œ (Okt ì‚¬ìš©)
python
ë³µì‚¬
í¸ì§‘
from konlpy.tag import Okt
import re

# í˜•íƒœì†Œ ë¶„ì„ê¸° ê°ì²´ ìƒì„±
okt = Okt()

# ì˜ˆì‹œ ë¬¸ì¥
text = "ì•ˆë…•í•˜ì„¸ìš”! ìì—°ì–´ì²˜ë¦¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. ğŸ˜Š #AI #NLP"

# 1) íŠ¹ìˆ˜ë¬¸ì ë° ì´ëª¨ì§€ ì œê±°
text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text)
print("íŠ¹ìˆ˜ë¬¸ì ì œê±°:", text)

# 2) í† í°í™” (í˜•íƒœì†Œ ë‹¨ìœ„)
tokens = okt.morphs(text)
print("í† í°í™”:", tokens)

# 3) ë¶ˆìš©ì–´ ì œê±° (ê°„ë‹¨ ì˜ˆì‹œ)
stopwords = ['ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì—', 'ì˜', 'ë„']
tokens = [word for word in tokens if word not in stopwords]
print("ë¶ˆìš©ì–´ ì œê±°:", tokens)

# 4) í•„ìš”ì‹œ ì–´ê°„ ì¶”ì¶œ ë˜ëŠ” í’ˆì‚¬ íƒœê¹… ê°€ëŠ¥
pos_tags = okt.pos(text)
print("í’ˆì‚¬ íƒœê¹…:", pos_tags)
3. ì£¼ìš” ì „ì²˜ë¦¬ ê³¼ì •
ë‹¨ê³„	ì„¤ëª…
íŠ¹ìˆ˜ë¬¸ì ì œê±°	ë¶ˆí•„ìš”í•œ ê¸°í˜¸, ì´ëª¨ì§€, ìˆ«ì ì œì™¸ ë“±
í† í°í™”	ë¬¸ì¥ì„ ë‹¨ì–´(ë˜ëŠ” í˜•íƒœì†Œ) ë‹¨ìœ„ë¡œ ë¶„ë¦¬
ë¶ˆìš©ì–´ ì œê±°	ì˜ë¯¸ ì—†ëŠ” ì¡°ì‚¬, ì ‘ì†ì‚¬ ë“± ì œê±°
ì •ê·œí™”	ë§ì¶¤ë²• êµì •, ì¤„ì„ë§ í™•ì¥, ì–´ê°„ ì¶”ì¶œ
í’ˆì‚¬ íƒœê¹…	ë‹¨ì–´ì— í’ˆì‚¬ ì •ë³´ ë¶€ì°© (ëª…ì‚¬, ë™ì‚¬ ë“± êµ¬ë¶„)

